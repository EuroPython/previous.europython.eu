{"pageProps":{"path":"/session/how-to-train-your-graphics-card-to-read","session":{"code":"CXADJQ","title":"How To Train Your Graphics Card (To Read)","speakers":[{"code":"F3JRJQ","name":"Matthew Carrigan","biography":"Hi! I used to be a biologist, then I became a computational biologist, and then I gave up all pretense and started coding full-time. I'm currently a machine learning engineer at Hugging Face, but sometimes I try to sneak in some protein models into my job, for old time's sake.","avatar":"https://program.europython.eu/media/avatars/matt_UBJfvPM.png","slug":"matthew-carrigan","affiliation":"Hugging Face","homepage":"https://huggingface.co/","twitter":"@carrigmat","biographySource":{"compiledSource":"var p=Object.defineProperty,c=Object.defineProperties;var g=Object.getOwnPropertyDescriptors;var a=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var m=(e,t,o)=>t in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,i=(e,t)=>{for(var o in t||(t={}))s.call(t,o)&&m(e,o,t[o]);if(a)for(var o of a(t))r.call(t,o)&&m(e,o,t[o]);return e},u=(e,t)=>c(e,g(t));var l=(e,t)=>{var o={};for(var n in e)s.call(e,n)&&t.indexOf(n)<0&&(o[n]=e[n]);if(e!=null&&a)for(var n of a(e))t.indexOf(n)<0&&r.call(e,n)&&(o[n]=e[n]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var n=o,{components:e}=n,t=l(n,[\"components\"]);return mdx(MDXLayout,u(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"Hi! I used to be a biologist, then I became a computational biologist, and then I gave up all pretense and started coding full-time. I'm currently a machine learning engineer at Hugging Face, but sometimes I try to sneak in some protein models into my job, for old time's sake.\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}}],"submission_type":"Tutorial","slug":"how-to-train-your-graphics-card-to-read","track":"PyData: Deep Learning, NLP, CV","state":"confirmed","abstract":"This tutorial aims to introduce new users to modern NLP using the open-source HuggingFace Transformers library. We'll use massive, pre-existing language models that you might have heard of like BERT and GPT to solve real-world tasks. By the end of this tutorial you'll be able to classify documents, get your computer to read a text and answer questions about it, and even translate between languages!","abstract_as_a_tweet":"How To Train Your Graphics Card (To Read): Go from zero to solving real-world tasks with state-of-the-art machine learning for text in a single tutorial!","description":"Note: Despite the title, no graphics card is needed! We will be using Colab notebooks for most of the tutorial. You can also run the notebooks on your local machine, but if you do that you'll need to install git-lfs to download some of the models we use.\r\n\r\nMost practical machine learning these days is \"supervised learning\". In supervised learning, we show a model a collection of example inputs and outputs, and train it to give the right output for each input. For example, we might show it pictures of animals, combined with a \"label\" for each picture like \"cat\" or \"dog\", in order to train it to identify which animal is in each photo. Or we could show it samples of text from Twitter posts, and give the tweets \"labels\" like \"toxic\" or \"not toxic\", in order to train it to identify unwanted tweets and filter them out automatically. In effect, the model learns to predict the correct \"label\" for any input that it sees.\r\n\r\nThe golden rule in supervised learning is that the more data you have, the better the model you can train. More data means more accuracy, whether the task is recognizing animals in images, or classifying text, or even driving a self-driving car. This is a real problem, though, when data collection isn't free; without a huge dataset of inputs and labels, it might be hard or impossible to train a model that's accurate enough for what you want it to do.\r\n\r\nProbably the single biggest revolution in machine learning in the last 5 years, particularly in NLP (natural language processing), has been the arrival of \"foundation models\", huge models trained for very long periods on vast amounts of text data. These models offer a solution to the problem of limited training data - by bringing a huge amount of linguistic prior knowledge with them, they greatly reduce the amount of data needed to learn a new task. In 2016, training a model to classify toxic comments might have required millions (or even tens of millions!) of examples and labels in order to achieve acceptable accuracy, but in 2022, we can start with a foundation model that already \"knows\" a lot about language, and achieve the same accuracy with a tiny fraction of that, and in a much shorter time, too!\r\n\r\nFoundation models can be intimidating, though - they're often created by industrial or academic research labs and published in papers that can be very impenetrable for people without a strong research background. In this tutorial, we'll show you how to abstract away that complexity and load, train and use foundation models without needing a Ph.D, or even any prior experience in machine learning! By the end of this 3-hour session, you should have the knowledge and code samples you need to train a better machine learning model than someone at the cutting edge of the field in 2016 could have achieved even with an entire research team.\r\n\r\nIn this course, we will use HuggingFace Transformers combined with the TensorFlow machine learning library. We will also use some of the most popular data science libraries in Python like Numpy and Pandas when preparing our data. You don't have to be familiar with any of these before attending the tutorial, and I'll do my best to explain what we're doing with them as we go! I don't assume any specific background in machine learning, and we won't need any advanced mathematics. I will, however, assume that you're reasonably fluent in Python!","duration":"180","python_level":"some","domain_level":"none","delivery":"in-person","room":"Wicklow Hall 2A","start":"2022-07-11T13:45:00+01:00","end":"2022-07-11T15:15:00+01:00","talks_in_parallel":["BRSSQK","DVDJWP"],"talks_after":[],"next_talk_code":null,"prev_talk_code":null,"website_url":"https://ep2022.europython.eu/session/how-to-train-your-graphics-card-to-read","type":"Tutorial","abstractSource":{"compiledSource":"var g=Object.defineProperty,m=Object.defineProperties;var p=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,u=Object.prototype.propertyIsEnumerable;var i=(e,t,o)=>t in e?g(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,s=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&i(e,o,t[o]);if(n)for(var o of n(t))u.call(t,o)&&i(e,o,t[o]);return e},l=(e,t)=>m(e,p(t));var d=(e,t)=>{var o={};for(var a in e)r.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&n)for(var a of n(e))t.indexOf(a)<0&&u.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=d(a,[\"components\"]);return mdx(MDXLayout,l(s(s({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"This tutorial aims to introduce new users to modern NLP using the open-source HuggingFace Transformers library. We'll use massive, pre-existing language models that you might have heard of like BERT and GPT to solve real-world tasks. By the end of this tutorial you'll be able to classify documents, get your computer to read a text and answer questions about it, and even translate between languages!\"))}MDXContent.isMDXComponent=!0;\n","scope":{}},"descriptionSource":{"compiledSource":"var u=Object.defineProperty,c=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var l=(e,t,a)=>t in e?u(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,i=(e,t)=>{for(var a in t||(t={}))r.call(t,a)&&l(e,a,t[a]);if(n)for(var a of n(t))s.call(t,a)&&l(e,a,t[a]);return e},h=(e,t)=>c(e,m(t));var d=(e,t)=>{var a={};for(var o in e)r.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&n)for(var o of n(e))t.indexOf(o)<0&&s.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=d(o,[\"components\"]);return mdx(MDXLayout,h(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"Note: Despite the title, no graphics card is needed! We will be using Colab notebooks for most of the tutorial. You can also run the notebooks on your local machine, but if you do that you'll need to install git-lfs to download some of the models we use.\"),mdx(\"p\",null,'Most practical machine learning these days is \"supervised learning\". In supervised learning, we show a model a collection of example inputs and outputs, and train it to give the right output for each input. For example, we might show it pictures of animals, combined with a \"label\" for each picture like \"cat\" or \"dog\", in order to train it to identify which animal is in each photo. Or we could show it samples of text from Twitter posts, and give the tweets \"labels\" like \"toxic\" or \"not toxic\", in order to train it to identify unwanted tweets and filter them out automatically. In effect, the model learns to predict the correct \"label\" for any input that it sees.'),mdx(\"p\",null,\"The golden rule in supervised learning is that the more data you have, the better the model you can train. More data means more accuracy, whether the task is recognizing animals in images, or classifying text, or even driving a self-driving car. This is a real problem, though, when data collection isn't free; without a huge dataset of inputs and labels, it might be hard or impossible to train a model that's accurate enough for what you want it to do.\"),mdx(\"p\",null,'Probably the single biggest revolution in machine learning in the last 5 years, particularly in NLP (natural language processing), has been the arrival of \"foundation models\", huge models trained for very long periods on vast amounts of text data. These models offer a solution to the problem of limited training data - by bringing a huge amount of linguistic prior knowledge with them, they greatly reduce the amount of data needed to learn a new task. In 2016, training a model to classify toxic comments might have required millions (or even tens of millions!) of examples and labels in order to achieve acceptable accuracy, but in 2022, we can start with a foundation model that already \"knows\" a lot about language, and achieve the same accuracy with a tiny fraction of that, and in a much shorter time, too!'),mdx(\"p\",null,\"Foundation models can be intimidating, though - they're often created by industrial or academic research labs and published in papers that can be very impenetrable for people without a strong research background. In this tutorial, we'll show you how to abstract away that complexity and load, train and use foundation models without needing a Ph.D, or even any prior experience in machine learning! By the end of this 3-hour session, you should have the knowledge and code samples you need to train a better machine learning model than someone at the cutting edge of the field in 2016 could have achieved even with an entire research team.\"),mdx(\"p\",null,\"In this course, we will use HuggingFace Transformers combined with the TensorFlow machine learning library. We will also use some of the most popular data science libraries in Python like Numpy and Pandas when preparing our data. You don't have to be familiar with any of these before attending the tutorial, and I'll do my best to explain what we're doing with them as we go! I don't assume any specific background in machine learning, and we won't need any advanced mathematics. I will, however, assume that you're reasonably fluent in Python!\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},"sessionsAfter":[],"sessionsInParallel":[{"code":"BRSSQK","title":"TDD in Python with pytest","speakers":[{"code":"7BS3PU","name":"Leonardo Giordani","biography":"Born in 1977 together with Star Wars, bash, Apple ][, Dire Straits, The Silmarillion, and many other great things.\r\n\r\nI started coding in April 1987 on a Sinclair ZX Spectrum. I then moved to MS-DOS PCs and in 1996 I started using Linux and became interested in operating system internals. I love software architectures, algorithms, mathematics and cryptography.\r\n\r\nIâ€™m mainly interested in open source software. I like both the theoretical and practical aspects of computer science.\r\n\r\nI am currently working as a contractor DevOps and Python developer while I design a DevOps bootcamp that I will run in London from October 2022.\r\n\r\nFrom 2013 I blog some technical thoughts at http://thedigitalcatonline.com.\r\n\r\nIn 2018 I published the free book â€œClean Architectures in Pythonâ€ http://bit.ly/getpycabook","avatar":"https://program.europython.eu/media/avatars/Avatar400x400_cuVmtE6.jpg","slug":"leonardo-giordani","affiliation":"The Digital Cat Services","homepage":"https://www.thedigitalcatonline.com/","twitter":"@tw_lgiordani"}],"submission_type":"Tutorial","slug":"tdd-in-python-with-pytest","track":"Testing","state":"confirmed","abstract":"This workshop will guide you step-by-step through the implementation of a very simple Python library following a strict TDD workflow. At the end of the workshop you will have grasped the main principles of TDD and learned the fundamentals of the Python testing library pytest.","abstract_as_a_tweet":"TDD in Python with pytest: learn how to write Python code following a test-driven development routine","description":"Test-Driven Development (TDD) is fortunately one of the names that I can spot most frequently when people talk about methodologies. Unfortunately, many programmers still do not follow it, fearing that it will impose a further burden on the already difficult life of a developer.\r\n\r\nTDD is a methodology, something that can help you to create better code. But it is not going to solve all your problems. As with all methodologies you have to pay attention not to commit blindly to it. Try to understand the reasons why certain practices are suggested by the methodology and you will also understand when and why you can or have to be flexible.\r\n\r\nDuring the workshop we will learn what TDD is, and what are the main rules. We will do this developing a very simple Python library together in a sort of a game that mirrors a daily TDD development routine. While we do this, we will also learn how to use pytest, which is one of the most used testing libraries in Python. Oh, we will also learn when NOT to follow the rules!\r\n\r\nSetup instructions:\r\n\r\n* Create and activate your Python virtual environment\r\n* `git clone https://github.com/lgiordani/simple_calculator`\r\n* `cd simple_calculator`\r\n* `git checkout --track origin/develop`\r\n* `pip install -r requirements/dev.txt`\r\n* You should be able to run `pytest -svv` and get an output like\r\n\r\n```\r\n================================ test session starts ===============================\r\nplatform linux -- Python XXXX, pytest-XXXX, py-XXXX, pluggy-XXXX --\r\ncabook/venv3/bin/python3\r\ncachedir: .cache\r\nrootdir: cabook/code/calc, inifile: pytest.ini\r\nplugins: cov-XXXX\r\ncollected 0 items \r\n\r\n=============================== no tests ran in 0.02s ==============================\r\n```","duration":"180","python_level":"none","domain_level":"none","delivery":"in-person","room":"Wicklow Hall 2B","start":"2022-07-11T13:45:00+01:00","end":"2022-07-11T15:15:00+01:00","talks_in_parallel":["CXADJQ","DVDJWP"],"talks_after":[],"next_talk_code":null,"prev_talk_code":null,"website_url":"https://ep2022.europython.eu/session/tdd-in-python-with-pytest"},{"code":"DVDJWP","title":"Build a production ready GraphQL API using Python","speakers":[{"code":"CWD3DM","name":"Patrick Arminio","biography":"Â¡Hello there! I'm Patrick, a Swiss-Italian living in London.\r\n\r\nI'm currently mainly working on Strawberry ðŸ“, a modern Python library for GraphQL. I'm a huge fan of GraphQL and also a Python user for more than 10 years now, so I'm super excited to contribute to the GraphQL ecosystem in Python.\r\n\r\nI'm also the Chair of Python Italia, the association that organises events around Python in Italy, I'm currently working on the new website for the conference with some friends.","avatar":"https://www.gravatar.com/avatar/489cdabedd1112f98474038939668778","slug":"patrick-arminio","affiliation":"Farbun","homepage":"https://patrick.wtf","twitter":"@patrick91"}],"submission_type":"Tutorial","slug":"build-a-production-ready-graphql-api-using-python","track":"Web","state":"confirmed","abstract":"This workshop will teach you how to create a production ready GraphQL API using Python and Strawberry. We will be using using Django as our framework of choice, but most of the concept will be applicable to other frameworks too.\r\n\r\nWe'll learn how GraphQL works under the hood, and how we can leverage type hints to create end to end type safe GraphQL queries.\r\n\r\nWe'll also learn how to authenticate users when using GraphQL and how to make sure our APIs are performant.\r\n\r\nIf we have enough time we'll take a look at doing realtime APIs using GraphQL subscriptions and how to use GraphQL with frontend frameworks such as React.","abstract_as_a_tweet":"Learn how to build a production GraphQL using @strawberry_gql in this workshop by @patrick91","description":"Note: to follow this tutorial make sure you setup your environment following the readme here: \r\n\r\nhttps://github.com/patrick91/strawberry-workshop\r\n\r\nAgenda of the worshop\r\n\r\n- Workshop introduction\r\n\t- The introduction will explain the goal of the workshop and make sure everyone is ready to start\r\n- Intro to type hints\r\n\t- Before looking at what GraphQL is, we'll do a short introduction on type hints in Python, since we'll be using the a lot during the workshop.\r\n- Introduction to GraphQL\r\n\t- Here we'll be looking at what GraphQL is, how it works and why it has been created\r\n- Our first GraphQL API\r\n\t- Here we'll get our hands dirty by creating our first GraphQL API using Strawberry. We'll also take time to see how to configure Strawberry with Django.\r\n- Let's test our API\r\n\t- I'm a big fan of TDD, so before continuing with our workshop we'll quickly see how to test our GraphQL API using pytest.\r\n- Schema design\r\n\t- In this section we'll spend time taking a look at how to design a GraphQL schema. We'll also understand the difference between queries and mutations.\r\n- Authentication\r\n\t- In this section we'll implement authentication to our GraphQL API. We'll discuss session based auth vs JWT authentication.\r\n- Performance / Monitoring / Observability\r\n\t- In this section we'll discuss how we can add observability/monitoring to our APIs and make sure we can keep our API performant over time.\r\n\t- We'll also see how we can use dataloaders to make our queries efficient. We'll also talk about other potential performance improvements (SQL optimisation, Static Queries and more)\r\n- **Bonus**\r\n\t- Integration with React\r\n\t\t- In this section we'll see how we can use GraphQL with a frontend framework like React.\r\n\t- Subscriptions\r\n\t\t- In this section we'll see what subscriptions are in GraphQL and how you can leverage them to build realtime APIs.","duration":"180","python_level":"some","domain_level":"some","delivery":"in-person","room":"Wicklow Hall 1","start":"2022-07-11T13:45:00+01:00","end":"2022-07-11T15:15:00+01:00","talks_in_parallel":["BRSSQK","CXADJQ"],"talks_after":[],"next_talk_code":null,"prev_talk_code":null,"website_url":"https://ep2022.europython.eu/session/build-a-production-ready-graphql-api-using-python"}]},"__N_SSG":true}